---
title: "NOAA Storm Data - Analysis of Significant Factors"
author: "Graham King"
date: "19 December 2014"
output: html_document
---

## Synopsis
The weather event causing most fatalities in the US since 1995 is Excessive Heat, closely followed by Tornado. Tornados cause by far the most injuries of any weather event.

I terms of economic cost, Drought has by far the most signficant impact, then Flood, followed by Hail, Hurricanes and Hurrican/Typhoon.

The granularity of the breakdown of the data by weather event could have an impact on the results.

****

## Introduction

This document seeks to perform some exploratory analysis on [https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2]("this") dataset of storm and weather events, published by the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database, in order to identify the most significant factors in terms of health and economic impact.

****

## Data Processing

This section makes use of some functions defined in another file:
```{r}
source("functions.R")
library(ggplot2)
library(reshape2)
```

### Sourcing the Data
```{r cache=TRUE}
filename <- "StormData.csv.bz2"
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"

if (!file.exists(filename)) {
    download.file(url=url, destfile = filename, method="curl")
}
raw.data.full <- read.csv(
    filename, header=TRUE, na.strings=c(""))
```

### First peek at the data
Having downloaded the data and read the file into variable `raw.data`, let's look at its structure:
```{r cache=TRUE}
raw.data <- raw.data.full #[rbinom(nrow(raw.data.full),1,0.2)==1,]
dim(raw.data)
str(raw.data)
```
In summary, this dataset contains 902297 observations of 37 variables.

How complete is the data? Let's look for NAs:
```{r}
nas <- c()
for (i in 1:37) nas[i] <- sum(is.na(raw.data[,i]))
names(nas) <- names(raw.data)
print(nas[nas>0])
```
There are quite a lot of NAs but not in variables I'm interested in for this report. I can handle Property/Crop damage exponents (`PROPDMGEXP` and `CROPDMGEXP`) by treating the associated damage number as an absolute value.

### Data Formatting
Firstly, let's remove columns we're not interested in:
```{r}
dtc <- raw.data[,
                -c(1,3,4,5,6,9,10,11,12,13,14,15,16,17,18,19,20,21,22,
                   29,30,31,32,33,34,35,36,37)]
```
The `BGN_DATE` variable is a factor, so this should be formatted as a Date:
```{r}
dtc[,"BGN_DATE"] <- as.Date(dtc[,"BGN_DATE"], "%m/%d/%Y %H:%M:%S")
dtc$year <- as.POSIXlt(as.Date(dtc[,"BGN_DATE"], "%m/%d/%Y %H:%M:%S"))$year+1900
```

The `EVTYPE` variable contains unnecessary whitespace, let's remove it:
```{r}
library(stringr)
dtc$EVTYPE <- factor(str_trim(dtc$EVTYPE))
```

Assessing property damage requires turning the numerical and exponential variables into a purely numerical value that can be used arithmetically. The values in the `PROPDMGEXP` and `CROPDMGEXP` do not correspond only to the 'K' (thousands), 'M' (millions) and 'B' (billions expected):
```{r}
table(dtc$PROPDMGEXP)
table(dtc$CROPDMGEXP)
```
Since we don't know how to treat many of these values, I'll remove them and use a helper function (`makenum`) to create a new column with absolute numbers (i.e 1B -> 1,000,000,000):
```{r cache=TRUE}
exp <- c("k", "K", "m", "M", "b", "B", "", NA)
dtc <- dtc[dtc$PROPDMGEXP %in% exp &
           dtc$CROPDMGEXP %in% exp,]
dtc$PROPDMGEXP <- factor(dtc$PROPDMGEXP)
dtc$CROPDMGEXP <- factor(dtc$CROPDMGEXP)
dtc$PROPDMGNUM <- mapply(makenum, dtc$PROPDMG, dtc$PROPDMGEXP)
dtc$CROPDMGNUM <- mapply(makenum, dtc$CROPDMG, dtc$CROPDMGEXP)
dtc$TOTALDMG <- dtc$CROPDMGNUM + dtc$CROPDMGNUM
```

The processed data now look like this:
```{r}
str(dtc)
head(dtc)
```

****

## Initial Questions
The following questions were addressed in order to get some familiarity with the data.

1. *How many events were recorded per year?*
```{r}
barplot(tapply(dtc$year, dtc$year, length),
        main = "Number of Weather Events Recorded by Year",
        ylab = "Total event count", xlab="Year")
nrow(dtc[dtc$year==min(dtc$year),])
nrow(dtc[dtc$year==max(dtc$year),])
```

This shows that there were very few events (`r nrow(dtc[dtc$year==min(dtc$year),])`) recorded in the earliest year (`r min(dtc$year)`) in the dataset, rising slowly during the 70s, 80s and early 90s before  suddenly increasing in the mid 90s and then rising more rapidly to a peak of `r nrow(dtc[dtc$year==max(dtc$year),])` in `r max(dtc$year)`

Given the low rate of data collection in the earlier years and the increased relevance of later data, I shall limit this analysis to data from 1995-2011.
```{r}
dtc <- dtc[dtc$year >=1995,]
```

2. *What are the most frequently occurring event types*
```{r}
by.evtype <- tapply(dtc$year, dtc$EVTYPE, length)
by.evtype <- as.data.frame(by.evtype[order(by.evtype, decreasing=TRUE)])
names(by.evtype) <- "count"
head(by.evtype)
```

****

## Most Harmful Weather Event
Group data by event type, summing up the number of injuries and fatalities for each event type; combine into a single health impact dataset and order first by number of fatalities then injuries.
```{r}
byinjuries <- as.data.frame(tapply(dtc$INJURIES, dtc$EVTYPE, sum))
byinjuries$EVTYPE<-row.names(byinjuries)
names(byinjuries) <- c("injuries", "evtype")
byfatalities <- as.data.frame(tapply(dtc$FATALITIES, dtc$EVTYPE, sum))
byfatalities$EVTYPE<-row.names(byfatalities)
names(byfatalities) <- c("fatalities", "evtype")

health <- merge(byinjuries, byfatalities)
health <- health[order(health$fatalities, health$injuries, decreasing = TRUE),]
health <- health[1:10,]
dimnames(health$fatalities) <- NULL
dimnames(health$injuries) <- NULL
health$evtype <- factor(health$evtype)

library(reshape2)
library(lattice)
hm <- melt(health, measure.vars=c("fatalities", "injuries"),
           id.vars="evtype", variable.name="type", value.name="count")
dim(hm$count) <- NULL
bp <- barchart(count ~ evtype | type, data=hm, ylab="Number of events",
               xlab = "Weather Event Type",
               main="Health impact of US weather events (1995-2011)",
               scales=list(y=list(relation="free"),x=list(rot=90)))
print(bp)
```

This figure shows that, by some distance, Tornados have the greatest effect on health both in terms of injuries and fatalities.

*Note that a limitation of the way that this data was sorted is that a weather event with huge numbers of injuries but few fatalities may not register.*

****

## Most Economically Damaging Weather Event


```{r}

bydmg <- as.data.frame(tapply(dtc$TOTALDMG, dtc$EVTYPE, sum))
bydmg$EVTYPE<-row.names(bydmg)
bydmg <- bydmg[order(bydmg[1], decreasing=TRUE),]
names(bydmg) <- c("cost", "evtype")

bn <- 10^9
scale <- signif(max(bydmg$cost, na.rm=TRUE), 1) / bn

library(ggplot2)
gc <- ggplot(bydmg[1:10,], aes(x=factor(evtype), y=cost))
gc <- gc + geom_bar(stat="identity")
gc <- gc + xlab("Event Type") + ylab("Total Cost ($)")
gc <- gc + ggtitle("Total cost of US weather events (1995-2011)")
gc <- gc + scale_y_continuous(
    breaks=bn * seq(0,scale, by=5),
    labels=paste0(seq(0,scale, by=5), "bn"),
    limits=bn * c(0,scale)
    )
gc <- gc + theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(gc)
```

This figure demonstrates that the most costly weather event is Drought, followed by Flood, then Hail, Hurricane and Hurricane/Typhoon.

This indicates that the granularity of weather event categorisation could result in some overlap, thus affecting the stated impact of certain weather events.

****

## Appendix 1 - Session Info
This report was produced on the following hardware setup:

Attribute | Detail
-- | --
OS | OS X Yosemite 10.10.1
Processor | 3.4 GHz Intel Core i7
Memory | 16GB 1333 MHz DDR3
Graphics | AMD Radeon HD 6970M 2048 MB

The R environment is as follows:
```{r}
sessionInfo()
```
R Studio version used is:
```
Version 0.98.1091 – © 2009-2014 RStudio, Inc.
Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/600.2.5 (KHTML, like Gecko)
```